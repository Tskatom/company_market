{
 "metadata": {
  "name": "Company_Market_Tweet_Content"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from dateutil import parser\n",
      "import sys\n",
      "from datetime import timedelta\n",
      "\n",
      "\"\"\"\n",
      "work steps:\n",
      "1> getting the stock price of these companies from yahoo\n",
      "2> get the annual report date of these companies from EDGAR\n",
      "3> compute the daily tweet count for these companies\n",
      "4> find the entities in the tweets\n",
      "5> find who are the guies most tweet about these companies\n",
      "6> which tweets of these companies has been retweeted many times(the retweets also capture some events, but it seems that \n",
      "people people only talk it and in the same day)\n",
      "7> compute the zscore of the stock market to check the \n",
      "\"\"\"\n",
      "\n",
      "mpwr_files = glob(\"/home/weiwang/workspace/data/topsy_50/MPWR*\")\n",
      "byd_files = glob(\"/home/weiwang/workspace/data/topsy_50/BYD*\")\n",
      "sape_files = glob(\"/home/weiwang/workspace/data/topsy_50/SAPE*\")\n",
      "\n",
      "\n",
      "def load_tweets_by_day(twteet_files):\n",
      "    \"\"\"\n",
      "    Group the tweets day by day\n",
      "    args:\n",
      "        tweet_files:  the tweet files list\n",
      "    returns:\n",
      "        tweets:  the tweets dictionary, key is date and value is the tweets list\n",
      "    \"\"\"\n",
      "    tweets = {}\n",
      "    for f in files:\n",
      "        with open(f) as tf:\n",
      "            for l in tf:\n",
      "                try:\n",
      "                    t = json.loads(l)\n",
      "                    dt = parser.parse(t['created_at']).strftime('%Y-%m-%d')\n",
      "                    if dt in tweets:\n",
      "                        tweets[dt].append(t)\n",
      "                    else:\n",
      "                        tweets[dt] = [t]\n",
      "                except:\n",
      "                    print \"Error:[%s]\\n%s\" % (sys.exc_info()[0], l)\n",
      "    return tweets\n",
      "\n",
      "def get_tweets_by_range(tweets, start, end):\n",
      "    \"\"\"\"\n",
      "    Get the tweets in a date range\n",
      "    args:\n",
      "        tweets:  the original tweets dictionary\n",
      "        start: the start date\n",
      "        end:  the end date\n",
      "    returns:\n",
      "        the tweets filtered by date range\n",
      "    \"\"\"\n",
      "    return {k:v for k,v in tweets.items() if k >= start and k <= end}\n",
      "\n",
      "def get_tweets_by_windows(tweets, day, window):\n",
      "    \"\"\"\"\n",
      "    Get the tweets in a date window\n",
      "    args:\n",
      "        tweets:  the original tweets dictionary\n",
      "        day: the indicator date\n",
      "        window: the size of the time window, it can be positive or negative\n",
      "    returns:\n",
      "        the tweets filtered by date window\n",
      "    \"\"\"\n",
      "    second_date = (parser.parse(day) - timedelta(days=window)).strftime(\"%Y-%m-%d\")\n",
      "    if day > second_date:\n",
      "        start = second_date\n",
      "        end = day\n",
      "    else:\n",
      "        start = day\n",
      "        end = second_date\n",
      "    return get_tweets_by_range(tweets, start, end)\n",
      "    \n",
      "\n",
      "byd_tweets = load_tweets_by_day(byd_files)\n",
      "                "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}