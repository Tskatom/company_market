{
 "metadata": {
  "name": "SAPE_Data_Process"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import glob\n",
      "import os\n",
      "import re\n",
      "import json\n",
      "tweets_folder = \"/raid/tskatom/company/SAPE/\"\n",
      "tweets_files = glob.glob(os.path.join(tweets_folder, \"*\"))\n",
      "tweets_out_folder = \"/raid/tskatom/company/CLEAN_SAPE/\"\n",
      "\n",
      "raw_count = 0\n",
      "new_count = 0\n",
      "tx = []\n",
      "missed = []\n",
      "for f in tweets_files:\n",
      "    basename = os.path.basename(f)\n",
      "    outf = os.path.join(tweets_out_folder, basename)\n",
      "    with open(f) as tf, open(outf, \"w\") as wf:\n",
      "        for line in tf:\n",
      "            tweet = json.loads(line)\n",
      "            content = tweet[\"text\"]\n",
      "            matched = re.findall(r'\\$SAPE|sapientnitro|sapientgm|sapientgov|sapient',content,re.I)\n",
      "            if len(matched) == 0:\n",
      "                missed.append(content)\n",
      "                \n",
      "            if len(matched) > 0:\n",
      "                raw_count += 1\n",
      "            if matched.count(\"sapient\") == len(matched) and len(matched)>0:\n",
      "                tx.append(content)\n",
      "                continue\n",
      "            wf.write(json.dumps(tweet)+\"\\n\")\n",
      "print raw_count, new_count                "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "49045 0\n"
       ]
      }
     ],
     "prompt_number": 19
    }
   ],
   "metadata": {}
  }
 ]
}